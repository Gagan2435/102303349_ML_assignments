{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 6"
      ],
      "metadata": {
        "id": "6r3_Jv9_DB12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 1"
      ],
      "metadata": {
        "id": "Y6c6svoNDLIH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t1PhVAXLCjB7"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data          # 4 features\n",
        "y = iris.target        # 3 classes: 0,1,2\n",
        "feature_names = iris.feature_names\n",
        "target_names = iris.target_names\n",
        "\n",
        "# Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Cell 3: GNB from scratch\n",
        "class MyGaussianNB:\n",
        "    \"\"\"\n",
        "    Simple Gaussian Naive Bayes:\n",
        "    - Priors: P(y=c) = count(c)/N\n",
        "    - Likelihood per feature (Gaussian):\n",
        "      p(x|y=c) = N(x; mean_{c,f}, var_{c,f})\n",
        "    - We work in log-space to avoid underflow.\n",
        "    \"\"\"\n",
        "    def __init__(self, var_smoothing=1e-9):\n",
        "        self.var_smoothing = var_smoothing  # small value to stabilize variance\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes_ = np.unique(y)\n",
        "        n_classes = len(self.classes_)\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        self.priors_log_ = {}\n",
        "        self.mean_ = {}\n",
        "        self.var_ = {}\n",
        "\n",
        "        for c in self.classes_:\n",
        "            Xc = X[y == c]\n",
        "            self.priors_log_[c] = np.log(Xc.shape[0] / X.shape[0])\n",
        "            # per-feature mean/var\n",
        "            mu = Xc.mean(axis=0)\n",
        "            var = Xc.var(axis=0) + self.var_smoothing\n",
        "            self.mean_[c] = mu\n",
        "            self.var_[c] = var\n",
        "        return self\n",
        "\n",
        "    def _log_gaussian(self, x, mu, var):\n",
        "        # elementwise log of Gaussian PDF (without constants combined)\n",
        "        return -0.5 * (np.log(2*np.pi*var) + ((x - mu)**2) / var)\n",
        "\n",
        "    def _joint_log_likelihood(self, X):\n",
        "        jll = []\n",
        "        for c in self.classes_:\n",
        "            mu = self.mean_[c]\n",
        "            var = self.var_[c]\n",
        "            # sum over features (naive independence)\n",
        "            log_likelihood = self._log_gaussian(X, mu, var).sum(axis=1)\n",
        "            jll.append(self.priors_log_[c] + log_likelihood)\n",
        "        return np.vstack(jll).T  # shape: [n_samples, n_classes]\n",
        "\n",
        "    def predict(self, X):\n",
        "        jll = self._joint_log_likelihood(X)\n",
        "        return self.classes_[np.argmax(jll, axis=1)]\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        jll = self._joint_log_likelihood(X)\n",
        "        # convert log-joint to normalized probabilities\n",
        "        # softmax\n",
        "        jll -= jll.max(axis=1, keepdims=True)\n",
        "        P = np.exp(jll)\n",
        "        P /= P.sum(axis=1, keepdims=True)\n",
        "        return P\n",
        "\n",
        "# Train & Evaluate our scratch model\n",
        "scratch_gnb = MyGaussianNB(var_smoothing=1e-9).fit(X_train, y_train)\n",
        "y_pred_scratch = scratch_gnb.predict(X_test)\n",
        "\n",
        "print(\"Accuracy (Scratch GNB):\", accuracy_score(y_test, y_pred_scratch))\n",
        "print(\"\\nConfusion Matrix (Scratch GNB):\\n\", confusion_matrix(y_test, y_pred_scratch))\n",
        "print(\"\\nClassification Report (Scratch GNB):\\n\", classification_report(y_test, y_pred_scratch, target_names=target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnDVPLlWCnlp",
        "outputId": "cfb9faf2-81ee-4725-8567-6d60ca5b0a2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Scratch GNB): 0.9666666666666667\n",
            "\n",
            "Confusion Matrix (Scratch GNB):\n",
            " [[10  0  0]\n",
            " [ 0  9  1]\n",
            " [ 0  0 10]]\n",
            "\n",
            "Classification Report (Scratch GNB):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      0.90      0.95        10\n",
            "   virginica       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Using sklearn GaussianNB\n",
        "sk_gnb = GaussianNB(var_smoothing=1e-9)\n",
        "sk_gnb.fit(X_train, y_train)\n",
        "y_pred_sk = sk_gnb.predict(X_test)\n",
        "\n",
        "print(\"Accuracy (sklearn GaussianNB):\", accuracy_score(y_test, y_pred_sk))\n",
        "print(\"\\nConfusion Matrix (sklearn GNB):\\n\", confusion_matrix(y_test, y_pred_sk))\n",
        "print(\"\\nClassification Report (sklearn GNB):\\n\", classification_report(y_test, y_pred_sk, target_names=target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkgonaTyCo16",
        "outputId": "921c5f18-620a-43d2-b6dc-c296cbe4f7f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (sklearn GaussianNB): 0.9666666666666667\n",
            "\n",
            "Confusion Matrix (sklearn GNB):\n",
            " [[10  0  0]\n",
            " [ 0  9  1]\n",
            " [ 0  0 10]]\n",
            "\n",
            "Classification Report (sklearn GNB):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      0.90      0.95        10\n",
            "   virginica       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 2"
      ],
      "metadata": {
        "id": "mv5BCaiGDHm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Pipeline + GridSearchCV for KNN\n",
        "# KNN ko scaling chahiye hoti hai, isliye Pipeline = StandardScaler -> KNN\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'knn__n_neighbors': list(range(1, 31)),\n",
        "    'knn__weights': ['uniform', 'distance'],\n",
        "    'knn__p': [1, 2]  # 1=Manhattan, 2=Euclidean\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,            # 5-fold cross-validation\n",
        "    n_jobs=-1,\n",
        "    return_train_score=False\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best CV Accuracy:\", grid.best_score_)\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "\n",
        "# Final evaluation on the held-out test set:\n",
        "best_model = grid.best_estimator_\n",
        "y_pred_knn = best_model.predict(X_test)\n",
        "print(\"\\nTest Accuracy (Best KNN):\", accuracy_score(y_test, y_pred_knn))\n",
        "print(\"\\nConfusion Matrix (Best KNN):\\n\", confusion_matrix(y_test, y_pred_knn))\n",
        "print(\"\\nClassification Report (Best KNN):\\n\", classification_report(y_test, y_pred_knn, target_names=target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CargUFvCsjN",
        "outputId": "e7cc0cce-c2f5-48d5-dad9-49dc3205b099"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best CV Accuracy: 0.975\n",
            "Best Params: {'knn__n_neighbors': 17, 'knn__p': 2, 'knn__weights': 'distance'}\n",
            "\n",
            "Test Accuracy (Best KNN): 0.9666666666666667\n",
            "\n",
            "Confusion Matrix (Best KNN):\n",
            " [[10  0  0]\n",
            " [ 0  9  1]\n",
            " [ 0  0 10]]\n",
            "\n",
            "Classification Report (Best KNN):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      0.90      0.95        10\n",
            "   virginica       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    }
  ]
}